{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5115f3a",
   "metadata": {},
   "source": [
    "## 1 Downloading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7280d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading dataset to train on.\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a06e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the dataset :  1115394\n"
     ]
    }
   ],
   "source": [
    "with open('../dataset.txt','r',encoding='utf-8') as data:\n",
    "    text = data.read()\n",
    "    \n",
    "print(\"Total number of characters in the dataset : \",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6575040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 characters :  First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print('First 100 characters : ', text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce157d",
   "metadata": {},
   "source": [
    "## 2 Processing The Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40526514",
   "metadata": {},
   "source": [
    "### 2.1 Building Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a58d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in the dataset = 65\n",
      "\n",
      "Which are following : \n",
      " \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print('Number of unique characters in the dataset =',vocab_size)\n",
    "print('\\nWhich are following : \\n',''.join(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a3fd2",
   "metadata": {},
   "source": [
    "### 2.2 Building Tokenizer  (Custom Encoder, Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb86ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping individual charaters to integers \n",
    "\n",
    "encoder = { char:i for i,char in enumerate(chars)}\n",
    "decoder = { i:char for i,char in enumerate(chars)}\n",
    "\n",
    "encode = lambda string: [encoder[char] for char in string]\n",
    "decode = lambda integers: [decoder[i] for i in integers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559d6fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Zain Khalid \n",
      "=  [38, 39, 47, 52, 1, 23, 46, 39, 50, 47, 42]\n",
      "\n",
      "Decoded  [38, 39, 47, 52, 1, 23, 46, 39, 50, 47, 42] \n",
      "= Zain Khalid\n"
     ]
    }
   ],
   "source": [
    "zk = encode('Zain Khalid')\n",
    "print('Encoded Zain Khalid \\n= ',zk)\n",
    "print('\\nDecoded ',zk,'\\n=', ''.join(decode(zk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1a115",
   "metadata": {},
   "source": [
    "### 2.3 Encoding The Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "609ce2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cfbf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,) <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "data = tf.convert_to_tensor(encode(text), dtype=tf.int64)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89246023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4595d52",
   "metadata": {},
   "source": [
    "### 2.4 Splitting the dataset (Train,Validate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df991356",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = int(0.9 * len(data))\n",
    "\n",
    "train_data = data[:limit]\n",
    "val_data = data[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7585e113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40352064",
   "metadata": {},
   "source": [
    "### 2.5 Chunking Dataset in Blocks (x,y) (To Train Transformer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f4984",
   "metadata": {},
   "source": [
    "#### Concept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c00bd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e0888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for input:  [18]   target is:  47\n",
      "for input:  [18, 47]   target is:  56\n",
      "for input:  [18, 47, 56]   target is:  57\n",
      "for input:  [18, 47, 56, 57]   target is:  58\n",
      "for input:  [18, 47, 56, 57, 58]   target is:  1\n",
      "for input:  [18, 47, 56, 57, 58, 1]   target is:  15\n",
      "for input:  [18, 47, 56, 57, 58, 1, 15]   target is:  47\n",
      "for input:  [18, 47, 56, 57, 58, 1, 15, 47]   target is:  58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for token in range(block_size):\n",
    "    context = x[:token+1]\n",
    "    target = y[token]\n",
    "    print('for input: ',context.numpy().tolist(),'  target is: ',target.numpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cccc4",
   "metadata": {},
   "source": [
    "#### Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78f863b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "(4, 8)\n",
      "tf.Tensor(\n",
      "[[ 1 41 56 53 61 52  8  0]\n",
      " [ 0  0 13 26 32 21 19 27]\n",
      " [57 47 42 43 56  1 44 59]\n",
      " [ 1 47 52 41 56 43 39 57]], shape=(4, 8), dtype=int64)\n",
      "targets:\n",
      "(4, 8)\n",
      "tf.Tensor(\n",
      "[[41 56 53 61 52  8  0 35]\n",
      " [ 0 13 26 32 21 19 27 26]\n",
      " [47 42 43 56  1 44 59 56]\n",
      " [47 52 41 56 43 39 57 43]], shape=(4, 8), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4 #Number of independent input sequences to process in parallel for GPU\n",
    "block_size = 8 #Maximum context length to make predictions\n",
    "n_embd = 32\n",
    "\n",
    "def get_batch(split):\n",
    "    #generate small batches of input x & target y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    randPos = tf.dtypes.cast(tf.random.uniform((batch_size,), minval=0, maxval=(len(data)-block_size)), dtype=tf.int32)\n",
    "    #print(randPos) # random positions in the whole datasets to grab block size chunks\n",
    "    xbatch = tf.stack([data[i:i+block_size] for i in randPos])\n",
    "    ybatch = tf.stack([data[i+1:i+block_size+1] for i in randPos])\n",
    "    \n",
    "    return xbatch, ybatch\n",
    "\n",
    "xbatch, ybatch = get_batch('train')\n",
    "\n",
    "print('inputs:')\n",
    "print(xbatch.shape)\n",
    "print(xbatch)\n",
    "\n",
    "print('targets:')\n",
    "print(ybatch.shape)\n",
    "print(ybatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a1ecbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for input:  [1]   target is:  41\n",
      "for input:  [1, 41]   target is:  56\n",
      "for input:  [1, 41, 56]   target is:  53\n",
      "for input:  [1, 41, 56, 53]   target is:  61\n",
      "for input:  [1, 41, 56, 53, 61]   target is:  52\n",
      "for input:  [1, 41, 56, 53, 61, 52]   target is:  8\n",
      "for input:  [1, 41, 56, 53, 61, 52, 8]   target is:  0\n",
      "for input:  [1, 41, 56, 53, 61, 52, 8, 0]   target is:  35\n",
      "for input:  [0]   target is:  0\n",
      "for input:  [0, 0]   target is:  13\n",
      "for input:  [0, 0, 13]   target is:  26\n",
      "for input:  [0, 0, 13, 26]   target is:  32\n",
      "for input:  [0, 0, 13, 26, 32]   target is:  21\n",
      "for input:  [0, 0, 13, 26, 32, 21]   target is:  19\n",
      "for input:  [0, 0, 13, 26, 32, 21, 19]   target is:  27\n",
      "for input:  [0, 0, 13, 26, 32, 21, 19, 27]   target is:  26\n",
      "for input:  [57]   target is:  47\n",
      "for input:  [57, 47]   target is:  42\n",
      "for input:  [57, 47, 42]   target is:  43\n",
      "for input:  [57, 47, 42, 43]   target is:  56\n",
      "for input:  [57, 47, 42, 43, 56]   target is:  1\n",
      "for input:  [57, 47, 42, 43, 56, 1]   target is:  44\n",
      "for input:  [57, 47, 42, 43, 56, 1, 44]   target is:  59\n",
      "for input:  [57, 47, 42, 43, 56, 1, 44, 59]   target is:  56\n",
      "for input:  [1]   target is:  47\n",
      "for input:  [1, 47]   target is:  52\n",
      "for input:  [1, 47, 52]   target is:  41\n",
      "for input:  [1, 47, 52, 41]   target is:  56\n",
      "for input:  [1, 47, 52, 41, 56]   target is:  43\n",
      "for input:  [1, 47, 52, 41, 56, 43]   target is:  39\n",
      "for input:  [1, 47, 52, 41, 56, 43, 39]   target is:  57\n",
      "for input:  [1, 47, 52, 41, 56, 43, 39, 57]   target is:  43\n"
     ]
    }
   ],
   "source": [
    "for row in range(batch_size):\n",
    "    for token in range(block_size):\n",
    "        context = xbatch[row, :token+1]\n",
    "        target = ybatch[row, token]\n",
    "        print('for input: ',context.numpy().tolist(),'  target is: ',target.numpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd33080",
   "metadata": {},
   "source": [
    "## 3 Bigram Language Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18899c",
   "metadata": {},
   "source": [
    "### 3.1 Model Architecture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8add0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class BigramLanguageModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, n_embd):\n",
    "        super(BigramLanguageModel, self).__init__()\n",
    "        self.token_embedding_table = tf.keras.layers.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = tf.keras.layers.Embedding(block_size, n_embd)\n",
    "        self.lm_head = tf.keras.layers.Dense(n_embd, vocab_size)\n",
    "\n",
    "    def call(self, idx, targets=None, training=False):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        tok_emd = self.token_embedding_table(idx)  # (B, T, C)\n",
    "        pos_emd = self.position_embedding_table(tf.range(T)) #(T, C)\n",
    "        x = tok_emd + pos_emd #(B,T,C) # Holds Token identities & position\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size) say C=n_embd\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = tf.reshape(logits, (B*T, C))\n",
    "            targets = tf.reshape(targets, (B*T,))\n",
    "            loss = tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets)\n",
    "            )\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx)\n",
    "            logits = logits[:, -1, :]  # (B, C)\n",
    "            probs = tf.nn.softmax(logits, axis=-1)  # (B, C)\n",
    "            idx_next = tf.random.categorical(tf.math.log(probs), 1)  # (B, 1)\n",
    "            idx = tf.concat([idx, idx_next], axis=1)  # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483b5bf",
   "metadata": {},
   "source": [
    "### 3.2 Model Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "\n",
    "\n",
    "logits, loss = model(xbatch, ybatch)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c50458",
   "metadata": {},
   "source": [
    "#### Untrained Model Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691139b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(''.join(decode(model.generate(idx=tf.zeros((1, 1), dtype=tf.int64), max_new_tokens=100).numpy()[0].tolist())))\n",
    "\n",
    "#Total Garbage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ae55d",
   "metadata": {},
   "source": [
    "### 3.3 Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_steps = 10000\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Sample a batch of data\n",
    "    xbatch, ybatch = get_batch('train')  # Assuming you have a function get_batch\n",
    "\n",
    "    # Evaluate the loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits, loss = model(xbatch, ybatch)\n",
    "\n",
    "    # Compute gradients and update weights\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "print('Loss = 'loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Somewhat stuctured results\n",
    "\n",
    "print(''.join(decode(model.generate(idx=tf.zeros((1, 1), dtype=tf.int64), max_new_tokens=500).numpy()[0].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9275a48e",
   "metadata": {},
   "source": [
    "# Adding Transformer  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caee8a0",
   "metadata": {},
   "source": [
    "## 4 Maths for self-attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d89c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want a method to preserve context for each word and it's former words in the time block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ebd8c3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for input:  [1]   target is:  41\n",
      "for input:  [1, 41]   target is:  56\n",
      "for input:  [1, 41, 56]   target is:  53\n",
      "for input:  [1, 41, 56, 53]   target is:  61\n",
      "for input:  [1, 41, 56, 53, 61]   target is:  52\n",
      "for input:  [1, 41, 56, 53, 61, 52]   target is:  8\n",
      "for input:  [1, 41, 56, 53, 61, 52, 8]   target is:  0\n",
      "for input:  [1, 41, 56, 53, 61, 52, 8, 0]   target is:  35\n"
     ]
    }
   ],
   "source": [
    "# example of words and their context\n",
    "\n",
    "for row in range(batch_size-3):\n",
    "    for token in range(block_size):\n",
    "        context = xbatch[row, :token+1]\n",
    "        target = ybatch[row, token]\n",
    "        print('for input: ',context.numpy().tolist(),'  target is: ',target.numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "047967c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbatch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3875f0b",
   "metadata": {},
   "source": [
    "### 4.1 Aggregating for context (simplest method) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbe55c",
   "metadata": {},
   "source": [
    "#### Version 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04857567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 2)\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2  # batch, time, channels\n",
    "x = tf.random.normal((B, T, C), dtype=tf.float64)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2817ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = tf.zeros((B, T, C), dtype=tf.float64)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1, :]  # (t, C)\n",
    "        mean_value = tf.reduce_mean(xprev, axis=0)\n",
    "        xbow = tf.tensor_scatter_nd_add(xbow, indices=[[b, t]], updates=[mean_value])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cf20914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 2), dtype=float64, numpy=\n",
       "array([[-1.14924009, -1.36499935],\n",
       "       [-0.80522729,  0.25705269],\n",
       "       [ 0.46568142, -0.49686646],\n",
       "       [-0.94495844,  0.50613577],\n",
       "       [ 0.36614164, -0.81278141],\n",
       "       [ 0.41970264, -0.05147407],\n",
       "       [-1.13084527, -0.83186565],\n",
       "       [ 1.37927137,  1.15312283]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n",
    "#original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a696dfb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8, 2), dtype=float64, numpy=\n",
       "array([[[-1.14924009, -1.36499935],\n",
       "        [-0.97723369, -0.55397333],\n",
       "        [-0.49626199, -0.53493771],\n",
       "        [-0.6084361 , -0.27466934],\n",
       "        [-0.41352055, -0.38229175],\n",
       "        [-0.27465002, -0.32715547],\n",
       "        [-0.39696363, -0.39925693],\n",
       "        [-0.17493425, -0.20520946]],\n",
       "\n",
       "       [[-0.11562781,  0.63718183],\n",
       "        [ 0.35645997,  0.8532918 ],\n",
       "        [-0.11393791,  0.167791  ],\n",
       "        [-0.11917604,  0.11351969],\n",
       "        [-0.41449325, -0.02157758],\n",
       "        [-0.72929212,  0.08856227],\n",
       "        [-0.7496213 , -0.01448659],\n",
       "        [-0.6781139 , -0.12349563]],\n",
       "\n",
       "       [[-2.18980136,  1.69369341],\n",
       "        [-0.87205705,  0.59489347],\n",
       "        [-0.61073565,  1.12653932],\n",
       "        [-0.76403204,  0.94550927],\n",
       "        [-0.86164589,  0.91549957],\n",
       "        [-0.9433301 ,  0.50503605],\n",
       "        [-0.68396538,  0.50864559],\n",
       "        [-0.7222557 ,  0.15176859]],\n",
       "\n",
       "       [[-0.05210129,  0.40729748],\n",
       "        [ 0.26322566,  0.12043353],\n",
       "        [-0.97262873, -0.61144175],\n",
       "        [-0.81782864, -1.01242203],\n",
       "        [-0.37378226, -1.06617895],\n",
       "        [-0.19309669, -0.76726068],\n",
       "        [-0.22791637, -0.41037051],\n",
       "        [-0.0752057 , -0.45676509]]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregated data\n",
    "xbow\n",
    "#each upcoming row is contains the aggregate of all previous "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd3b2c",
   "metadata": {},
   "source": [
    "### 4.2 Efficient aggregating for context (simplest method) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101d7be",
   "metadata": {},
   "source": [
    "#### Concept (Same achived through matrix multiplication trick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a418a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a lower triangular matrix\n",
    "a = tf.linalg.band_part(tf.ones((3, 3), dtype=tf.float64), -1, 0)\n",
    "a = a / tf.reduce_sum(a, axis=1, keepdims=True)\n",
    "\n",
    "# Create a random matrix with integer values between 0 and 10\n",
    "b = tf.constant(np.random.randint(0, 10, size=(3, 2)).astype(np.float64))\n",
    "\n",
    "# Perform matrix multiplication\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "# Print the results\n",
    "print('a=')\n",
    "print(a.numpy())\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b.numpy())\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd3b1ea",
   "metadata": {},
   "source": [
    "#### Version 2 (Reproducing xbow via matrix mulitplication instead of loop multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.linalg.band_part(tf.ones((T, T), dtype=tf.float64), -1, 0) \n",
    "weights = weights / tf.reduce_sum(weights, axis=1, keepdims=True)\n",
    "\n",
    "# Round each value to 3 decimal points for better visibility\n",
    "weights_numpy_rounded = np.round(weights.numpy().tolist(), decimals=3)\n",
    "weights_numpy_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d59b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow2 = tf.matmul(weights, x) # Here (B,T,T) x (B,T,C) = (B,T,C).   where B in (B,T,T) was automatically created by tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('xbow = ',xbow[0].numpy())\n",
    "print('\\nSame as\\n')\n",
    "print('xbow2 = ',xbow2[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c88fd8",
   "metadata": {},
   "source": [
    "#### Version 3 (Using softmax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lower triangular matrix and initialize wei with zeros\n",
    "tril = tf.linalg.band_part(tf.ones((T, T), dtype=tf.float64), -1, 0)\n",
    "weights = tf.zeros((T, T), dtype=tf.float64)\n",
    "\n",
    "# Mask the upper triangular part with -inf\n",
    "weights = tf.where(tf.equal(tril, 0), float('-inf'), weights)\n",
    "\n",
    "# Apply softmax along the last dimension\n",
    "weights = tf.nn.softmax(weights, axis=-1)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "xbow3 = tf.matmul(weights, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('xbow = ',xbow[0].numpy())\n",
    "print('\\nSame as\\n')\n",
    "print('xbow2 = ',xbow3[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be8f95",
   "metadata": {},
   "source": [
    "### 4.3 Self-attention mechanism context (better method)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf0401",
   "metadata": {},
   "source": [
    "#### Version 4 (Reproducing xbow via matrix mulitplication instead of loop multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lower triangular matrix and initialize wei with zeros\n",
    "tril = tf.linalg.band_part(tf.ones((T, T), dtype=tf.float64), -1, 0)\n",
    "weights = tf.zeros((T, T), dtype=tf.float64)\n",
    "\n",
    "# Mask the upper triangular part with -inf\n",
    "weights = tf.where(tf.equal(tril, 0), float('-inf'), weights)\n",
    "\n",
    "# Apply softmax along the last dimension\n",
    "weights = tf.nn.softmax(weights, axis=-1)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "xbow3 = tf.matmul(weights, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5638ce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 8, 32])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 32  # batch, time, channels\n",
    "x = tf.random.normal((B, T, C))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6173e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape :  (4, 8, 32)\n",
      "k.shape :  (4, 8, 16)\n",
      "q.shape :  (4, 8, 16)\n",
      "wei.shape :  (4, 8, 8)\n",
      "(4, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "\n",
    "key = tf.keras.layers.Dense(head_size, use_bias=False)\n",
    "query = tf.keras.layers.Dense(head_size, use_bias=False)\n",
    "value = tf.keras.layers.Dense(head_size, use_bias=False)\n",
    "\n",
    "print('x.shape : ', x.shape)\n",
    "k = key(x)   # (B, T, 32) => (B, T, 16)\n",
    "q = query(x) # (B, T, 32) => (B, T, 32)\n",
    "print('k.shape : ', k.shape)\n",
    "print('q.shape : ', q.shape)\n",
    "\n",
    "wei = tf.matmul(q, tf.transpose(k, perm=[0, 2, 1]))  # (B, T, T)\n",
    "\n",
    "print('wei.shape : ',wei.shape)\n",
    "\n",
    "tril = tf.linalg.band_part(tf.ones((T, T), dtype=tf.float64), -1, 0)\n",
    "wei = tf.where(tf.equal(tril, 0), float('-inf'), wei)\n",
    "\n",
    "# Apply softmax along the last dimension\n",
    "wei = tf.nn.softmax(wei, axis=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = tf.matmul(wei, v)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d523d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd841bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [9.8463178e-01, 1.5368149e-02, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [4.5601367e-03, 2.5054205e-02, 9.7038573e-01, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [9.7832882e-01, 2.1538427e-02, 2.3295534e-06, 1.3044475e-04,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.9321831e-09, 9.9971753e-01, 2.8247354e-04, 2.3293320e-10,\n",
       "        2.6625002e-10, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.6792955e-06, 1.8783492e-05, 3.6958933e-02, 2.0531880e-02,\n",
       "        9.3633085e-01, 6.1577610e-03, 0.0000000e+00, 0.0000000e+00],\n",
       "       [3.9879506e-04, 3.6720667e-06, 4.4227920e-05, 9.7426558e-01,\n",
       "        1.3631139e-02, 1.1653907e-02, 2.6310336e-06, 0.0000000e+00],\n",
       "       [9.0681368e-01, 3.0532675e-03, 1.0505347e-03, 8.7144729e-03,\n",
       "        4.8647649e-05, 2.5347555e-03, 7.7304922e-02, 4.7961657e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae2838",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc0e32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tf.random.normal((B, T, head_size))\n",
    "q = tf.random.normal((B, T, head_size))\n",
    "\n",
    "wei = q @ tf.transpose(k, perm=[0, 2, 1]) * head_size**-0.5 #scaling after transpose, check below to see whyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "256b8325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746931"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(k).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8c6f728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0030558"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(q).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67e6a5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0009656"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(wei).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fec94ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1924978 , 0.14260589, 0.23511736, 0.14260589, 0.287173  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(tf.constant([0.1, -0.2, 0.3, -0.2, 0.5]), axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9cd5671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03260834, 0.00295816, 0.1615102 , 0.00295816, 0.79996514],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without scaling the softmax favours larger values big time as visible\n",
    "tf.nn.softmax(tf.constant([0.1, -0.2, 0.3, -0.2, 0.5])*8, axis=-1).numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d832f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
